{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d8ca1aa8cc344709b3840155443eef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f53cc6880cde4d5d95553c5c7217b7f4",
              "IPY_MODEL_c7d9121786bb4e2493f8e4c2a76b7241",
              "IPY_MODEL_5b5376d6c6854161b2bfb4e045081dcc"
            ],
            "layout": "IPY_MODEL_0f4eb0027c82483296ff1762eff957c4"
          }
        },
        "f53cc6880cde4d5d95553c5c7217b7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00db8dabf93c45ba9a18c2518b36ff0d",
            "placeholder": "​",
            "style": "IPY_MODEL_c938aa7e0aa94147ae201d62b3d41828",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c7d9121786bb4e2493f8e4c2a76b7241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea39ce5627045d4aecce908c2cda836",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e7d7d32c12744da9e589b198174abd8",
            "value": 3
          }
        },
        "5b5376d6c6854161b2bfb4e045081dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b66af001d0d544909cae525fd13749d0",
            "placeholder": "​",
            "style": "IPY_MODEL_0e700c050ab0460486d9536610467e75",
            "value": " 3/3 [01:16&lt;00:00, 24.63s/it]"
          }
        },
        "0f4eb0027c82483296ff1762eff957c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00db8dabf93c45ba9a18c2518b36ff0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c938aa7e0aa94147ae201d62b3d41828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ea39ce5627045d4aecce908c2cda836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7d7d32c12744da9e589b198174abd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b66af001d0d544909cae525fd13749d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e700c050ab0460486d9536610467e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTveoVRvMM5E",
        "outputId": "80a4b590-b7e7-43ac-83c9-d132faf7d180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes==0.41.3 in /usr/local/lib/python3.10/dist-packages (0.41.3)\n",
            "Requirement already satisfied: accelerate==0.25.0 in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (2.4.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers==4.37.2\n",
        "!pip install bitsandbytes==0.41.3 accelerate==0.25.0\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q gradio\n",
        "!pip install -q gTTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig, pipeline\n",
        "\n",
        "model_id = 'llava-hf/llava-1.5-7b-hf'\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_compute_dtype = torch.float16\n",
        ")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"image-to-text\",\n",
        "    model = model_id,\n",
        "    model_kwargs = {'quantization_config': quant_config}\n",
        ")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "9d8ca1aa8cc344709b3840155443eef8",
            "f53cc6880cde4d5d95553c5c7217b7f4",
            "c7d9121786bb4e2493f8e4c2a76b7241",
            "5b5376d6c6854161b2bfb4e045081dcc",
            "0f4eb0027c82483296ff1762eff957c4",
            "00db8dabf93c45ba9a18c2518b36ff0d",
            "c938aa7e0aa94147ae201d62b3d41828",
            "6ea39ce5627045d4aecce908c2cda836",
            "0e7d7d32c12744da9e589b198174abd8",
            "b66af001d0d544909cae525fd13749d0",
            "0e700c050ab0460486d9536610467e75"
          ]
        },
        "id": "L_2eC2HIMfTF",
        "outputId": "1d177b72-92fd-49de-abb1-94d110f2516b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d8ca1aa8cc344709b3840155443eef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import gradio as gr\n",
        "import time\n",
        "import warnings\n",
        "import os\n",
        "from gtts import gTTS\n",
        "from PIL import Image\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "kwog9LTrM1kb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "#Log File\n",
        "tstamp = datetime.datetime.now()\n",
        "tstamp = str(tstamp).replace(\" \", \"_\")\n",
        "logfile = f\"log_{tstamp}.txt\"\n",
        "\n",
        "def writehistory(text):\n",
        "    with open(logfile, 'a', encoding='utf-8') as f:\n",
        "        f.write(text)\n",
        "        f.write('\\n')\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "N9zp2CzYM6Q5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "\n",
        "def img2txt(input_text, input_image):\n",
        "  image = Image.open(input_image)\n",
        "  writehistory(f'Input text: {input_text} - Type: {type(input_text)} - Dir: {dir(input_text)}')\n",
        "  if type(input_text) == tuple:\n",
        "    prompt_instructions = \"\"\"\n",
        "    Describe the image using as much details as possible.\n",
        "    You are a helpful AI Assistant who is able to answer questions about the image.\n",
        "    What is the image all about?\n",
        "    Now generate the helpful answer.\"\"\"\n",
        "  else:\n",
        "    prompt_instructions = \"\"\"\n",
        "    Act as an expert in imagery descriptive analysis, using as much detail as possible from the image\n",
        "    \"\"\" + input_text\n",
        "  writehistory(f'Prompt Instructions: {prompt_instructions}')\n",
        "  prompt = \"User: <image>\\n\" + prompt_instructions + \"\\nAssistant:\"\n",
        "  outputs = pipe(image, prompt = prompt, generate_kwargs= {\"max_new_tokens\": 200})\n",
        "  #print(outputs)\n",
        "  #Extract the response text\n",
        "  if outputs is not None and len(outputs[0]['generated_text']) > 0:\n",
        "    match = re.search(r'Assistant:\\s*(.*)', outputs[0][\"generated_text\"])\n",
        "    if match:\n",
        "      response = match.group(1)\n",
        "    else:\n",
        "      response = 'No response found.'\n",
        "  else:\n",
        "    response = 'No response generated.'\n",
        "  return response\n",
        "\n",
        "#response = img2txt('what is this image about?', 'image.png')"
      ],
      "metadata": {
        "id": "x4HfgmNUM8d1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe (audio):\n",
        "  if audio is None or audio == '':\n",
        "    return ('','',None)\n",
        "\n",
        "  model = whisper.load_model(\"medium\", device = device)\n",
        "\n",
        "  audio = whisper.load_audio(audio)\n",
        "  audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "  mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "  _, probs = model.detect_language(mel)\n",
        "\n",
        "  options = whisper.DecodingOptions()\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  result_text = result.text\n",
        "  return result_text"
      ],
      "metadata": {
        "id": "wJFLZ22uNAjh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text2speech(text, file_path):\n",
        "  audioobj = gTTS(text = text, lang = 'en', slow = False)\n",
        "  audioobj.save(file_path)\n",
        "  return file_path"
      ],
      "metadata": {
        "id": "oloDlRi3NBPl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This step and command is needed else the next line will show an error message\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "OT0gW-8PNDE2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -f lavfi -i anullsrc=r=44100:cl=mono -t 10 -q:a 9 -acodec libmp3lame audio_file.mp3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06yPSaYKNE0v",
        "outputId": "d35219b5-6eed-406e-8b5d-9aea361a43ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, lavfi, from 'anullsrc=r=44100:cl=mono':\n",
            "  Duration: N/A, start: 0.000000, bitrate: 352 kb/s\n",
            "  Stream #0:0: Audio: pcm_u8, 44100 Hz, mono, u8, 352 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (pcm_u8 (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'audio_file.mp3':\n",
            "  Metadata:\n",
            "    TSSE            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: mp3, 44100 Hz, mono, s16p\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \rsize=      39kB time=00:00:09.97 bitrate=  32.2kbits/s speed= 115x    \n",
            "video:0kB audio:39kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.568409%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_inputs(audio_path, image_path):\n",
        "  #Extracting the text from the audio\n",
        "  speech2text_output = transcribe(audio_path)\n",
        "\n",
        "  #Transforming the text to an image\n",
        "  if image_path:\n",
        "    text_output = img2txt(speech2text_output, image_path)\n",
        "  else:\n",
        "    text_output = 'No image provided.'\n",
        "\n",
        "  #Transforming the text to an audio\n",
        "  audio_output = text2speech(text_output, \"audio_file.mp3\")\n",
        "\n",
        "  return speech2text_output, text_output, audio_output"
      ],
      "metadata": {
        "id": "_bajWPmPNINM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradio interface\n",
        "import gradio as gr\n",
        "import base64\n",
        "import os\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn = process_inputs,\n",
        "    inputs = [\n",
        "        gr.Audio(sources=['microphone'], type='filepath'),\n",
        "        gr.Image(type='filepath')\n",
        "    ],\n",
        "    outputs = [\n",
        "        gr.Textbox(label='Speech to Text'),\n",
        "        gr.Textbox(label='Text Output'),\n",
        "        gr.Audio('audio_file.mp3')\n",
        "    ],\n",
        "    title = 'Voice Assistant for multimodal data',\n",
        "    description = 'Upload an image and interact via voice input and audio reponse'\n",
        ")\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "CyaSehmUNLBN",
        "outputId": "5c646734-bcd5-4c13-8fa5-cb8cf45fdb26"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://4b458d054a83c12ffe.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4b458d054a83c12ffe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://4b458d054a83c12ffe.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}